# ğŸ¤– Chatty AI

Simple **Retrieval-Augmented Generation (RAG)** application that lets you chat with your documents using AI. 

![Chatty AI Screenshot](src/images/ChattyAI.png)

## Features

- **ğŸ“š Document Intelligence**: Upload and chat with your documents using natural language
- **ğŸ” Smart Search**: Advanced vector search powered by OpenAI embeddings
- **ğŸ’¬ Conversational AI**: Interactive chat interface with context-aware responses
- **ğŸš€ Fast & Efficient**: Built on LanceDB for lightning-fast vector operations
- **ğŸ¨ Beautiful UI**: Clean, modern Streamlit interface
- **ğŸ”’ Privacy-First**: Your documents stay local, only queries are sent to OpenAI

## Architecture

```
Chatty AI
â”œâ”€â”€ ğŸ“„ Document Processing (embedding.py)
â”œâ”€â”€ ğŸ—„ï¸ Vector Database (LanceDB)
â”œâ”€â”€ ğŸ¤– AI Chat Interface (rag.py)
â””â”€â”€ ğŸŒ Web UI (Streamlit)
```

## Quick Start

### Prerequisites

- Python 3.9+
- OpenAI API key
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/ambra19/chatty-ai-rag.git
   cd chatty-ai
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   # Edit .env and add your OpenAI API key
   OPENAI_API_KEY=your_api_key_here
   ```

4. **Prepare your documents**
   - Place your documents in the `src/data/` folder (repo comes with some mock-up data created by me)
   - Tested format only in: `.docx`

5. **Generate embeddings**
   ```bash
   cd src/rag
   python embedding.py
   ```

6. **Launch the app**
   ```bash
   streamlit run rag.py
   ```

### Customization

- **Model**: Change the AI model in `rag.py`
- **Search Results**: Adjust `num_results` in the `get_context` function
- **Temperature**: Modify response creativity in the OpenAI API call

### Made with â¤ï¸ in Amsterdam